var tipuesearch = {"pages":[{"title":"About","text":"Me Hi, I'm Francisco! I'm currently a Computer Vision Data Scientist at CCC, where I work on combining photo and telematics data to enhance our suite of AI-enabled vehicle collision estimating tools. I received my Master's in Aerospace Engineering from the University of Illinois at Urbana-Champaign where explored the applications of deep learning to computational modeling. Since then I've been passionate about teaching computers to how to learn from images, simulations, and other complex and dynamic data.","tags":"pages","url":"/pages/about.html","loc":"/pages/about.html"},{"title":"Research","text":"Research Interests My research interests and experience lie at the intersection of deep learning, computational modeling, and complex systems. Specifically, I'm interested in using deep learning methods to better understand and model complex and dynamic data. Deep Learning + Computational Modeling Learning nonlinear reduced order models Many fields, particularly in the physical sciences, are in the fortunate position of having models based on first-principles that describe the evolution of certain systems with near-perfect accuracy. Notable examples include the Navier-Stokes equations in fluid mechanics or Schrödinger's equation in quantum mechanics. Although in principle it is possible to numerically solve these equations through direct numerical simulations, this often yields systems of equations with millions or billions of degrees of freedom. Even with recent advances in computational power and memory capacity solving these high-fidelity models is still computationally intractable for multi-query and time-critical applications such as design optimization, uncertainty quantification, and model predictive control. Although there are a wide variety of principled strategies for constructing reduced order models from data, most are intrusive as they require access to the system operators. Further, some systems may require special treatment of nonlinearities to ensure computational efficiency or additional modeling to preserve stability. The recent rise in deep learning and big data have driven a shift in the way complex spatiotemporal systems are modeled. In a recent work titled Deep convolutional recurrent autoencoders for learning low-dimensional feature dynamics of fluid systems we develop a deep learning based, completely data-driven approach to model reduction. At the core of this approach is an extension of projection-based model reduction in which a low-dimensional representation of the high-dimensional data is learned in the form of coordinates on an expressive nonlinear manifold. The dynamics of this representation on the underlying manifold are also learned using a representative collection of solution snapshots. Deep dilation models for multi-scale dynamics Recurrent neural networks (RNNs) have long been used to model sequential or time-dependent data. However, many real-world physical systems, e.g., turbulent flow in fluids, exhibit multi-scale dynamics. Thus, while RNNs can accurately model the dynamics of a system at one time-scale, they fail to capture the dynamics occurring over a multitude of scales. This problem is not unique to physical systems: RNNs also fail to capture the varying time-scales evident in speech data. Recent work involving models with dilated RNNs and convolutional networks, e.g., WaveNet (see figure), have shown great performance in modeling multi-scale speech data. Currently, I am developing deep dilation models inspired by WaveNet to help improve deep learning based modeling of multi-scale physical systems. This work attempts to explore the how dilated RNNs help capture dynamics at different scales, and thereby significantly increasing the applicability of deep learning based modeling approaches to real-world dynamical systems. High-Performance Computing Quinoa: Adapative Computational Fluid Dynamics As we enter the exascale era of high-performance computing performance of computational physics codes will increasingly depend on their ability to asynchronously adapt to varying computational loads induced by multi-scale and multi-physics simulations as well as varying hardware performance. During my time at Los Alamos National Laboratory I contributed to the development of Quinoa , an open-source computational science code specifically addressing the challenges that will be faced with heterogeneous exascale machines. Quinoa is built on top of the Charm++ runtime system which allows for asynchronous parallel execution enabling the overlapping of computation, communication, and I/O. In future work, I would like to incorporate deep learning based methods into Quinoa for asynchronous parallel modeling based solely on multi-scale and multi-physics data.","tags":"pages","url":"/pages/research.html","loc":"/pages/research.html"},{"title":"Publications","text":"Publications 2019 Gonzalez, F. , Balajewicz, M. (2019) Dilated recurrent neural networks for learning multi-scale dynamics (Working paper) 2018 Gonzalez, F. , Balajewicz, M. (2018) Deep convolutional recurrent autoencoders for learning low-dimensional feature dynamics of fluid systems , arXiv preprint arXiv:1808.01346 ( Submitted to International Journal of Numerical Methods in Fluids ) 2016 Gonzalez, F. , Rogers, B. (2016) Asynchronous Navier-Stokes solver for unstructured grids using overdecomposition, Los Alamos National Laboratory Tech. Rep. LA-UR-16-27258, 104-124. Conference Proceedings 2017 Bakosi, J., Bird, R., Junghans, C., Pavel, R., Waltz, J., Gonzalez, F. , Rogers, B. (2017) Quinoa: Adaptive Computational Fluid Dynamics, 15th Annual Workshop on Charm++ and its Applications, Urbana, IL. 2016 Gonzalez, F. (2016) Numerical simulation of highly pulsatile blood flow through idealized femoral artery bifurcations, 2016 Undergraduate Research Symposium, Urbana, IL. 2015 Gonzalez, F. (2015) Gain scheduling approach to variable pitch vertical axis wind turbines, 2015 SAEOPP McNair/SSS Scholars Research Conference, Atlanta, GA. (2nd Place Oral Presentation Award) Gonzalez, F. (2015) Parallelized 2D vortex panel model for rotating airfoils, 2015 Undergraduate Research Symposium, Urbana, IL.","tags":"pages","url":"/pages/publications.html","loc":"/pages/publications.html"},{"title":"Curriculum Vitae","text":"Education M.Sc. , Aerospace Engineering, University of Illinois at Urbana-Champaign, 2018 Thesis: Learning low-dimensional feature dynamics using convolutional recurrent autoencoders Adviser: Maciej Balajewicz B.Sc. , Aerospace Engineering, University of Illinois at Urbana-Champaign, 2016 Cum Laude , Minor: Computational Science & Engineering Experience 2018 - Present Computer Vision Data Scientist , CCC , Chicago, IL AI-enabled vehicle collision estimating tools • Developing deep learning tools that leverage photos and telematics data for vehicle claims automation 2016 - 2018 Graduate Research Assistant , University of Illinois at Urbana-Champaign , Urbana, IL Data-driven model order reduction • Developed deep learning based, completely data-driven nonlinear model reduction strategy • Currently researching applications of deep learning to modeling complex dynamical systems Summer 2018 Research Intern , Mitsubishi Electric Research Laboratory , Cambridge, MA Optimal sensor placement for state estimation • Developed optimal sensor placement algorithm for state estimation of large thermo-fluid systems • Implemented iterative solvers for large-scale matrix equations used in estimation Summer 2016 Computational Physics Fellow , Los Alamos National Laboratory , Los Alamos, NM Quinoa: Adaptive Computational Fluid Dynamics • Contributed to the development of Quinoa, a fully asynchronous distributed-memory parallel finite element solver using unstructured grids • Implemented load-balancing capabilities on the finite element solver using the Charm++ runtime system 2015 - 2016 Blue Waters Research Intern , National Center for Supercomputing Applications , Urbana, IL Computational bio-fluid mechanics • Utilized the petascale supercomputer, Blue Waters, to investigate and develop residual-based turbulence models applicable to arterial blood flow • Designed and ran simulations investigating intracranial blood flow during +Gz accelerations 2014 - 2016 Ronald E. McNair Scholar , University of Illinois at Urbana-Champaign , Urbana, IL Computational aerodynamics • Proposed an independent research project on the aerodynamics of vertical axis wind turbines • Developed a vortex code to study rotating airfoils under changing tip-speed ratios and blade pitch angles Honors & Awards 2018-2020 Alfred P. Sloan MPhD Scholar , UIUC/Alfred P. Sloan Foundation (declined offer) 2016-2018 SURGE Fellowship , UIUC College of Engineering 2014-2016 Ronald E. McNair Scholar , UIUC 2015-2016 Blue Waters Student Fellowship , National Center for Supercomputing Applications 2013-2016 Edmund J. James Scholar , UIUC College of Engineering 2014, 2015 Dean's List , UIUC College of Engineering 2012-2016 Presidents' Award Program Honors Scholarship , UIUC 2015 David Kuck Computational Science & Engineering Award , UIUC 2015 La Casa Latina Outstanding Scholar Award , UIUC Teaching Fall 2016 Teaching Assistant , CSE High Performance Computing Workshop, NCSA 2013-2014 Mathematics Tutor , Office of Minority Student Affairs, UIUC Software Experience Languages & Frameworks Programming • Python, C/C++, MATLAB, Fortran 90 Machine Learning • TensorFlow, Keras, Scikit-learn, AWS SageMaker Big Data • PySpark High Performance Computing • OpenMP, MPI, CUDA, Charm++ Packages nMOR: Neural Model Order Reduction • Deep learning based package for nonlinear model order reduction written in Python and Tensorflow, available on Github . Download PDF Version (updated 04/06/19)","tags":"pages","url":"/pages/cv.html","loc":"/pages/cv.html"}]};